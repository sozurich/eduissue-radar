
import streamlit as st
import pandas as pd
import re
from collections import Counter
from datetime import datetime
import requests
import openai
from openai import OpenAI
import time

# Initialize session state for summary request
if 'summary_requested' not in st.session_state:
    st.session_state['summary_requested'] = False

# 1. Kakao í…ìŠ¤íŠ¸ íŒŒì‹±
def parse_kakao_text(file):
    text = file.read().decode('utf-8')
    lines = text.splitlines()
    parsed = []
    current_date = None
    date_pattern = r'-{10,}\s*(\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼.*?)\s*-{10,}'
    msg_pattern = r'\[(.*?)\] \[(ì˜¤ì „|ì˜¤í›„) (\d{1,2}:\d{2})\] (.+)'
    for line in lines:
        dm = re.match(date_pattern, line)
        if dm:
            current_date = dm.group(1)
            continue
        mm = re.match(msg_pattern, line)
        if mm and current_date:
            user, ampm, time_str, msg = mm.groups()
            hour, minute = map(int, time_str.split(':'))
            if ampm == 'ì˜¤í›„' and hour != 12:
                hour += 12
            timestamp = f"{hour:02}:{minute:02}"
            parsed.append({"ë‚ ì§œ": current_date, "ì‚¬ìš©ì": user, "ì‹œê°„": timestamp, "ë©”ì‹œì§€": msg})
    return pd.DataFrame(parsed)

# 2. ë¯¼ì› í‚¤ì›Œë“œ ì¶”ì¶œ
issue_keywords = ["ë°°ì†¡","ì§€ì—°","ëˆ„ë½","ë¶ˆëŸ‰","ë¶€ì¡±","ì •ì‚°","ë°˜í’ˆ","ì¶”ê°€","ì˜¤ë¥˜"]
def extract_issues(df):
    msgs = df[df['ë©”ì‹œì§€'].str.contains('|'.join(issue_keywords))]
    words = ' '.join(msgs['ë©”ì‹œì§€'].tolist())
    nouns = re.findall(r'[\uAC00-\uD7A3]+', words)
    cnt = Counter(nouns)
    return msgs, cnt.most_common(10)

# 3. ë„¤ì´ë²„ OpenAPI ë‰´ìŠ¤ í¬ë¡¤ë§
def crawl_naver_openapi(query):
    client_id = st.secrets.get("NAVER_CLIENT_ID")
    client_secret = st.secrets.get("NAVER_CLIENT_SECRET")
    if not client_id or not client_secret:
        st.error("NAVER API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return []
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }
    params = {"query": query + " êµê³¼ì„œ", "display": 5, "sort": "date"}
    res = requests.get("https://openapi.naver.com/v1/search/news.json", headers=headers, params=params)
    if res.status_code != 200:
        st.error(f"ë„¤ì´ë²„ API ì˜¤ë¥˜: {res.status_code}")
        return []
    items = res.json().get("items", [])
    results = []
    for it in items:
        title = it.get("title","").replace("<b>","").replace("</b>","")
        link = it.get("originallink") or it.get("link")
        date_str = it.get("pubDate","")
        try:
            pub = datetime.strptime(date_str,'%a, %d %b %Y %H:%M:%S %z')
        except:
            pub = datetime.now()
        results.append({"ì œëª©": title, "ë§í¬": link, "ë‚ ì§œ": pub, "í‘œì‹œë‚ ì§œ": pub.strftime('%Y-%m-%d')})
    return results

# 4. GPT ìš”ì•½ with backoff
def summarize_with_gpt(messages):
    api_key = st.secrets.get("OPENAI_API_KEY")
    if not api_key:
        st.error("OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return ""
    client = OpenAI(api_key=api_key)
    prompt = ("ì•„ë˜ëŠ” êµê³¼ì„œ ê´€ë ¨ ë¯¼ì› ë©”ì‹œì§€ ëŒ€í™”ì…ë‹ˆë‹¤. ì£¼ìš” ì´ìŠˆì™€ ë¶„ìœ„ê¸°ë¥¼ "
              "3~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n\n" + "\n".join(messages))
    for i in range(3):
        try:
            resp = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role":"user","content":prompt}],
                temperature=0.7,
            )
            return resp.choices[0].message.content
        except Exception:
            time.sleep(2**i)
    st.warning("ìš”ì²­ì´ ë§ì•„ ìš”ì•½ì„ ì ì‹œ í›„ì— ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    return "ìš”ì•½ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

@st.cache_data(ttl=3600)
def summarize_cached(messages):
    return summarize_with_gpt(messages)

# 5. ê¸°ì‚¬ ë Œë”ë§
def render_articles(articles):
    if not articles:
        st.markdown("ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for art in articles:
            with st.container():
                st.markdown(f"**{art['ì œëª©']}** ({art['í‘œì‹œë‚ ì§œ']})")
                st.link_button("ğŸ”— ë‰´ ìŠ¤ ë³´ëŸ¬ê°€ê¸°", url=art["ë§í¬"])

# 6. Streamlit UI
st.title("ğŸ“š EduIssue Radar")
st.markdown("êµê³¼ì„œ ë¯¼ì› ë©”ì‹œì§€ ë¶„ì„ ë° ë„¤ì´ë²„ OpenAPI ë‰´ìŠ¤ ìš”ì•½")

uploaded = st.file_uploader("ì¹´ì¹´ì˜¤í†¡ ì±„íŒ… .txt íŒŒì¼ ì—…ë¡œë“œ", type="txt")
if uploaded:
    df = parse_kakao_text(uploaded)
    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'].str.extract(r'(\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼)')[0],
                                format='%Yë…„ %mì›” %dì¼', errors='coerce').dt.date
    min_d, max_d = df['ë‚ ì§œ'].min(), df['ë‚ ì§œ'].max()
    st.markdown(f"**ë¶„ì„ ê°€ëŠ¥í•œ ë‚ ì§œ:** {min_d} ~ {max_d}")
    sd, ed = st.date_input("ë¶„ì„ ê¸°ê°„ ì„ íƒ", [min_d, max_d])
    df_sel = df[(df['ë‚ ì§œ'] >= sd) & (df['ë‚ ì§œ'] <= ed)]
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë¯¼ì› ë¶„ì„","ğŸ“° ì—°ê´€ ë‰´ìŠ¤","ğŸ“ GPT ìš”ì•½"])
    with tab1:
        st.success(f"{sd} ~ {ed} ë©”ì‹œì§€ {len(df_sel)}ê±´ ë¶„ì„")
        iss_df, top = extract_issues(df_sel)
        st.subheader("ğŸš¨ ë¯¼ì› ë©”ì‹œì§€")
        st.write(iss_df[['ë‚ ì§œ','ì‹œê°„','ì‚¬ìš©ì','ë©”ì‹œì§€']])
        st.markdown("**ë¯¼ì› í‚¤ì›Œë“œ TOP10**")
        for i in range(0,len(top),3):
            cols = st.columns(3)
            for j,(kw,cnt) in enumerate(top[i:i+3]):
                cols[j].markdown(f"- **{kw}** ({cnt}íšŒ)")
    with tab2:
        st.subheader("ğŸ“° ì—°ê´€ ë‰´ìŠ¤")
        _,top_issues = extract_issues(df_sel)
        for kw,_ in top_issues[:3]:
            with st.expander(f"ğŸ” {kw} ê´€ë ¨ ë‰´ìŠ¤"):
                render_articles(crawl_naver_openapi(kw))
    with tab3:
        st.subheader("ğŸ“ GPT ìš”ì•½")
        msgs = df_sel["ë©”ì‹œì§€"].tolist()
        if msgs:
            scope = st.selectbox("ìš”ì•½ ë²”ìœ„ ì„ íƒ",["ì „ì²´ ë©”ì‹œì§€","ìµœì‹  ë©”ì‹œì§€ ê°œìˆ˜"])
            if scope=="ìµœì‹  ë©”ì‹œì§€ ê°œìˆ˜":
                n = st.slider("ìµœì‹  ëª‡ ê±´ì„ ìš”ì•½í• ê¹Œìš”?",50,500,200,50)
                snippet = msgs[-n:]
            else:
                snippet = msgs
            if st.button("âœ… ìš”ì•½ ìš”ì²­"):
                st.session_state['summary_requested']=True
            if st.session_state['summary_requested']:
                summary = summarize_cached(tuple(snippet))
                st.write(summary)
            else:
                st.markdown("ë²„íŠ¼ì„ ëˆŒëŸ¬ ìš”ì•½ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            st.markdown("ë¶„ì„í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
